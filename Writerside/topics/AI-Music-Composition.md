# AI Music Composition

<!--Writerside adds this topic when you create a new documentation project.
You can use it as a sandbox to play with Writerside features, and remove it from the TOC when you don't need it anymore.
If you want to re-add it for your experiments, click + to create a new topic, choose Topic from Template, and select the 
"Starter" template.-->

## Results

The speed of generating a simple music clip for AI is very fast, it requires only about one to two minutes to compose a 45-second music clip.

Example of Intro generated by AI

<video src="85bpmIntro.mp4"/>

Example of Climax generated by AI

<video src="85bpmClimax.mp4"/>

Example of Outro generated by AI

<video src="85bpmOutro.mp4"/>

Discussion: We can see that each separated clip is good result, but when they are combined together, they cannot match the style. Given that they are trained with the same clips of music sample, same statistics and same prompt with the same AI model. The difference is just they get sample from different part of same clips of music. Therefore, it still requires a long training or arrangement process.

However, it is hard for AI to get sample from the whole song but not the separate part. Here is one of the output

## Using OpenAI JukeBox

In the current stage, we still need to use a lot of prompts which is no natural language to give command to the AI model to generate a music clip. This is an example of JukeBox prompt.

```Shell
mpiexec -n {ngpus} python jukebox/train.py --hps=small_vqvae,small_prior,all_fp16,cpu_ema --name=small_prior \
--sample_length=2097152 --bs=4 --audio_files_dir={audio_files_dir} --labels=False --train --test --aug_shift --aug_blend \
--restore_vqvae=logs/small_vqvae/checkpoint_latest.pth.tar --prior --levels=2 --level=1 --weight_decay=0.01 --save_iters=1000
```

### Usage explaination
`mpiexec -n {ngpus} python jukebox/train.py`:  This part of the command is using MPI (Message Passing Interface) to run the training script on multiple GPUs. The number of GPUs is specified by the variable `ngpus`.

### Specified options

--hps=small_vqvae,small_prior,all_fp16,cpu_ema
: Specifies the hyperparameters for training. It includes configurations for the small VQ-VAE, small prior, mixed-precision training (all_fp16), and CPU-based exponential moving average (cpu_ema).

--name=small_prior
: Sets the name of the training run to "small_prior."

--sample_length=2097152
: Sets the length of the training samples. In this case, the samples are 2,097,152 audio samples long.

--bs=4
: Sets the batch size for training. The batch size is 4.

--audio_files_dir=[audio_files_dir]
: Specifies the directory containing the audio files for training. The actual directory path is expected to be provided for `audio_files_dir`.

--labels=False
: Indicates whether the training data includes labels. In this case, it's set to False, suggesting that the training data does not have associated labels.

--train --test
: Specifies that the script should perform both training and testing. Training is to update the model parameters, while testing is often used to evaluate the model's performance on a validation set.

--aug_shift --aug_blend
: Enables data augmentation by shifting and blending the audio during training.

--restore_vqvae=logs/small_vqvae/checkpoint_latest.pth.tar
: Specifies the path to restore the VQ-VAE model from a checkpoint. The prior model often relies on the features learned by the VQ-VAE.

--prior --levels=2 --level=1
: Indicates that the training is for the prior model (--prior), and the prior model is at level=1 out of levels=2. The prior model typically involves generating coarse features.

--weight_decay=0.01
: Sets the weight decay, which is a regularization term applied during training to prevent overfitting.

--save_iters=1000
: Specifies the interval at which the model checkpoints will be saved. In this case, a checkpoint will be saved every 1000 iterations.

Discussion: Writing prompts to AI model is still a difficult job for the general public. Only people with professional knowledge in coding can understand and write this code easily.